{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NnuRIZedJmK"
   },
   "source": [
    "## Content Based Filtering by hand\n",
    "\n",
    "This lab illustrates how to implement a content based filter using low level Tensorflow operations.  \n",
    "The code here follows the technique explained in Module 2 of Recommendation Engines: Content Based Filtering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this lab, we need to use TensorFlow version 1.13.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.13.1\n",
      "  Downloading https://files.pythonhosted.org/packages/d2/ea/ab2c8c0e81bd051cc1180b104c75a865ab0fc66c89be992c4b20bbf6d624/tensorflow-1.13.1-cp27-cp27mu-manylinux1_x86_64.whl (92.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 92.5MB 11kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.6 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/21/56/4bcec5a8d9503a87e58e814c4e32ac2b32c37c685672c30bc8c54c6e478a/Keras_Applications-1.0.8.tar.gz (289kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 4.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mock>=2.0.0 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/d6/c3/65db90ec27181edf491c26aa998ae631e50cd1f04ee8d8d513a95e3937f3/grpcio-1.23.0-cp27-cp27mu-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.2MB 534kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "\u001b[K    100% |████████████████████████████████| 368kB 3.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.13.3 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/b1/3367ea1f372957f97a6752ec725b87886e12af1415216feec9067e31df70/numpy-1.16.5-cp27-cp27mu-manylinux1_x86_64.whl (17.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.0MB 68kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting backports.weakref>=1.0rc1 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.1.6 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/0d/7cbf64cac3f93617a2b6b079c0182e4a83a3e7a8964d3b0cc3d9758ba002/absl-py-0.8.0.tar.gz (102kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 9.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/00/83/b4a77d044e78ad1a45610eb88f745be2fd2c6d658f9798a15e384b7d57c9/wheel-0.33.6-py2.py3-none-any.whl\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/89/ac/48dd71c2bdc8d31e367f9b72f25ccb3b89bc6b9d664fee21f9a8efa5714d/tensorboard-1.13.1-py2-none-any.whl (3.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 383kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.10.0 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/04/4e36c33f8eb5c5b6c622a1f4859352a6acca7ab387257d4b3c191d23ec1d/gast-0.3.2.tar.gz\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 9.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.6.1 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/98/de/2ac9a18d675f5537f24e70de890352ad5f34324553cedc55073414d61f6d/protobuf-3.9.2-cp27-cp27mu-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 958kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting enum34>=1.1.6 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/db/e56e6b4bbac7c4a06de1c50de6fe1ef3810018ae11732a50f15f62c7d050/enum34-1.1.6-py2-none-any.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting h5py (from keras-applications>=1.0.6->tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/12/90/3216b8f6d69905a320352a9ca6802a8e39fdb1cd93133c3d4163db8d5f19/h5py-2.10.0-cp27-cp27mu-manylinux1_x86_64.whl (2.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.8MB 438kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting funcsigs>=1; python_version < \"3.3\" (from mock>=2.0.0->tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Collecting futures>=2.2.0; python_version < \"3.2\" (from grpcio>=1.8.6->tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/a6/f46ae3f1da0cd4361c344888f59ec2f5785e69c872e175a748ef6071cdb5/futures-3.3.0-py2-none-any.whl\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
      "\u001b[K    100% |████████████████████████████████| 327kB 3.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 10.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting setuptools (from protobuf>=3.6.1->tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/86/095d2f7829badc207c893dd4ac767e871f6cd547145df797ea26baea4e2e/setuptools-41.2.0-py2.py3-none-any.whl (576kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 2.0MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: keras-applications, termcolor, absl-py, gast\n",
      "  Running setup.py bdist_wheel for keras-applications ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/dd/f2/5d/2689b5547f32c4e258c3b7ccbe7f1d0f2afbb84fb01e830792\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/9a/1e/7a/456008eb5e47fd5de792c6139df6d5b3d5f71d51c6a0b94799\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/59/38/c6/234dc39b4f6951a0768fbc02d5b7207137a5b1d9094f0d54bf\n",
      "Successfully built keras-applications termcolor absl-py gast\n",
      "Installing collected packages: numpy, six, h5py, keras-applications, funcsigs, mock, futures, enum34, grpcio, absl-py, tensorflow-estimator, termcolor, backports.weakref, wheel, setuptools, protobuf, werkzeug, markdown, tensorboard, gast, keras-preprocessing, astor, tensorflow\n",
      "Successfully installed absl-py-0.8.0 astor-0.8.0 backports.weakref-1.0.post1 enum34-1.1.6 funcsigs-1.0.2 futures-3.3.0 gast-0.3.2 grpcio-1.23.0 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 mock-3.0.5 numpy-1.16.5 protobuf-3.9.2 setuptools-41.2.0 six-1.12.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 werkzeug-0.16.0 wheel-0.33.6\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.13.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to restart your kernel to ensure this change has taken place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IzbZLmz1dJmL",
    "outputId": "f4f882d9-6752-4b8d-8d7d-83eb61690d89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "36uCjFhldJmR"
   },
   "source": [
    "To start, we'll create our list of users, movies and features. While the users and movies represent elements in our database, for a content-based filtering method the features of the movies are likely hand-engineered and rely on domain knowledge to provide the best embedding space. Here we use the categories of Action, Sci-Fi, Comedy, Cartoon, and Drama to describe our movies (and thus our users).\n",
    "\n",
    "In this example, we will assume our database consists of four users and six movies, listed below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ElQV43fxdJmS"
   },
   "outputs": [],
   "source": [
    "users = ['Ryan', 'Danielle',  'Vijay', 'Chris']\n",
    "movies = ['Star Wars', 'The Dark Knight', 'Shrek', 'The Incredibles', 'Bleu', 'Memento']\n",
    "features = ['Action', 'Sci-Fi', 'Comedy', 'Cartoon', 'Drama']\n",
    "\n",
    "num_users = len(users)\n",
    "num_movies = len(movies)\n",
    "num_feats = len(features)\n",
    "num_recommendations = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s6iJCViqdJmU"
   },
   "source": [
    "### Initialize our users, movie ratings and features\n",
    "\n",
    "We'll need to enter the user's movie ratings and the k-hot encoded movie features matrix. Each row of the users_movies matrix represents a single user's rating (from 1 to 10) for each movie. A zero indicates that the user has not seen/rated that movie. The movies_feats matrix contains the features for each of the given movies. Each row represents one of the six movies, the columns represent the five categories. A one indicates that a movie fits within a given genre/category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0asiLTwdJmV"
   },
   "outputs": [],
   "source": [
    "# each row represents a user's rating for the different movies\n",
    "users_movies = tf.constant([\n",
    "                [4,  6,  8,  0, 0, 0],\n",
    "                [0,  0, 10,  0, 8, 3],\n",
    "                [0,  6,  0,  0, 3, 7],\n",
    "                [10, 9,  0,  5, 0, 2]],dtype=tf.float32)\n",
    "\n",
    "# features of the movies one-hot encoded\n",
    "# e.g. columns could represent ['Action', 'Sci-Fi', 'Comedy', 'Cartoon', 'Drama']\n",
    "movies_feats = tf.constant([\n",
    "                [1, 1, 0, 0, 1],\n",
    "                [1, 1, 0, 0, 0],\n",
    "                [0, 0, 1, 1, 0],\n",
    "                [1, 0, 1, 1, 0],\n",
    "                [0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 1]],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCW5BtGudJmX"
   },
   "source": [
    "### Computing the user feature matrix\n",
    "\n",
    "We will compute the user feature matrix; that is, a matrix containing each user's embedding in the five-dimensional feature space.  We can calculuate this as the matrix multiplication of the `users_movies` tensor with the `movies_feats` tensor. Implement this in the TODO below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "isMCBMOFdJmY",
    "outputId": "cf7eaa50-95ab-4e8f-916b-27c26d6421dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2, shape=(4, 5), dtype=float32, numpy=\n",
       "array([[10., 10.,  8.,  8.,  4.],\n",
       "       [ 3.,  0., 10., 10., 11.],\n",
       "       [13.,  6.,  0.,  0., 10.],\n",
       "       [26., 19.,  5.,  5., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_feats = tf.matmul(users_movies,movies_feats)\n",
    "users_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ps7XXoYwdJmc"
   },
   "source": [
    "Next we normalize each user feature vector to sum to 1. Normalizing isn't strictly neccesary, but it makes it so that rating magnitudes will be comparable between users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "y81EeooodJmc",
    "outputId": "904beb39-0a6f-49e0-971f-5198003e7adb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6, shape=(4, 5), dtype=float32, numpy=\n",
       "array([[0.25      , 0.25      , 0.2       , 0.2       , 0.1       ],\n",
       "       [0.0882353 , 0.        , 0.29411766, 0.29411766, 0.32352942],\n",
       "       [0.44827586, 0.20689656, 0.        , 0.        , 0.3448276 ],\n",
       "       [0.3880597 , 0.2835821 , 0.07462686, 0.07462686, 0.17910448]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_feats = users_feats/tf.reduce_sum(users_feats,axis=1,keepdims=True)\n",
    "users_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kqOPr51tdJmf"
   },
   "source": [
    "#### Ranking feature relevance for each user\n",
    "\n",
    "We can use the users_feats computed above to represent the relative importance of each movie category for each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "PKLqAD3adJmg",
    "outputId": "d535513e-72cd-4120-ef6d-82424efb20d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=10, shape=(4, 5), dtype=int32, numpy=\n",
       "array([[0, 1, 2, 3, 4],\n",
       "       [4, 2, 3, 0, 1],\n",
       "       [0, 4, 1, 2, 3],\n",
       "       [0, 1, 4, 2, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_users_features = tf.nn.top_k(users_feats, num_feats)[1]\n",
    "top_users_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "pvUmu7MUdJmj",
    "outputId": "a9e89bb0-330b-4687-866e-0f209910d8c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ryan: ['Action', 'Sci-Fi', 'Comedy', 'Cartoon', 'Drama']\n",
      "Danielle: ['Drama', 'Comedy', 'Cartoon', 'Action', 'Sci-Fi']\n",
      "Vijay: ['Action', 'Drama', 'Sci-Fi', 'Comedy', 'Cartoon']\n",
      "Chris: ['Action', 'Sci-Fi', 'Drama', 'Comedy', 'Cartoon']\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_users):\n",
    "    feature_names = [features[index] for index in top_users_features[i]]\n",
    "    print('{}: {}'.format(users[i],feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yne0CyZMdJmn"
   },
   "source": [
    "### Determining movie recommendations. \n",
    "\n",
    "We'll now use the `users_feats` tensor we computed above to determine the movie ratings and recommendations for each user.\n",
    "\n",
    "To compute the projected ratings for each movie, we compute the similarity measure between the user's feature vector and the corresponding movie feature vector.  \n",
    "\n",
    "We will use the dot product as our similarity measure. In essence, this is a weighted movie average for each user.\n",
    "\n",
    "*Hint: you can also implement this as a matrix multiplication, but you will have to transpose one of the operands*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "dxdctrYDdJmn",
    "outputId": "e294f23e-f7bd-409f-8a30-2d39f9174e01"
   },
   "outputs": [],
   "source": [
    "users_ratings =  #TODO\n",
    "users_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o07wODzddJmq"
   },
   "source": [
    "The computation above finds the similarity measure between each user and each movie in our database. To focus only on the ratings for new movies, we apply a mask to the all_users_ratings matrix.  \n",
    "\n",
    "If a user has already rated a movie, we ignore that rating. This way, we only focus on ratings for previously unseen/unrated movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "xUgOnV3AdJmr",
    "outputId": "2672899f-d626-4e33-e730-7d8b051a3954"
   },
   "outputs": [],
   "source": [
    "users_ratings_new = tf.where(tf.equal(users_movies, tf.zeros_like(users_movies)),\n",
    "                                  users_ratings,\n",
    "                                  tf.zeros_like(tf.cast(users_movies, tf.float32)))\n",
    "users_ratings_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YyNvH46zdJmu"
   },
   "source": [
    "Finally let's grab and print out the top 2 rated movies for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "PdDGgmSpdJmv",
    "outputId": "a921b943-383b-4984-cffd-e0eb5c7ab41e"
   },
   "outputs": [],
   "source": [
    "top_movies = tf.nn.top_k(users_ratings_new, num_recommendations)[1]\n",
    "top_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "dCB7Dv9_dJmx",
    "outputId": "0d00e5c6-f7bc-4fae-a359-283f2fdb1c4c"
   },
   "outputs": [],
   "source": [
    "for i in range(num_users):\n",
    "    movie_names = [movies[index] for index in top_movies[i]]\n",
    "    print('{}: {}'.format(users[i],movie_names))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "content_based_by_hand.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
